{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e597ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\SU_RL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a946f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=5, stride=1, padding=2, padding_mode='zeros')\n",
    "        self.LRN1 = nn.LocalResponseNorm(size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2, padding_mode='zeros')\n",
    "        self.LRN2 = nn.LocalResponseNorm(size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1, padding_mode='zeros')\n",
    "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1, padding_mode='zeros')\n",
    "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1, padding_mode='zeros')\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(256 * 7 * 7, 4096)\n",
    "        self.Drop1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(4096, 2)\n",
    "        self.Drop2 = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.LRN1(F.relu(self.conv1(x),inplace=True)))\n",
    "        x = self.pool2(self.LRN2(F.relu(self.conv2(x),inplace=True)))\n",
    "        x = F.relu(self.conv3(x),inplace=True)\n",
    "        x = F.relu(self.conv4(x),inplace=True)\n",
    "        x = self.pool3(F.relu(self.conv5(x),inplace=True))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x),inplace=True)\n",
    "        x = self.Drop1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.Drop2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bdc74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, epoch, optimizer, criterion, train_dataloader):\n",
    "    print('[ Train epoch: %d ]' % epoch)\n",
    "    net.train() # 모델을 학습 모드로 설정\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad() # 기울기(gradient) 초기화\n",
    "\n",
    "        outputs = net(inputs) # 모델 입력하여 결과 계산\n",
    "        loss = criterion(outputs, targets) # 손실(loss) 값 계산\n",
    "        loss.backward() # 역전파를 통해 기울기(gradient) 계산\n",
    "\n",
    "        optimizer.step() # 계산된 기울기를 이용해 모델 가중치 업데이트\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print('Train accuarcy:', 100. * correct / total)\n",
    "    print('Train average loss:', train_loss / total)\n",
    "    return (100. * correct / total, train_loss / total)\n",
    "\n",
    "\n",
    "def validate(net, epoch, val_dataloader):\n",
    "    print('[ Validation epoch: %d ]' % epoch)\n",
    "    net.eval() # 모델을 평가 모드로 설정\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(val_dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = net(inputs) # 모델 입력하여 결과 계산\n",
    "        val_loss += criterion(outputs, targets).item()\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print('Accuarcy:', 100. * correct / total)\n",
    "    print('Average loss:', val_loss / total)\n",
    "    return (100. * correct / total, val_loss / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239a8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): csv 파일의 경로.\n",
    "            transform (callable, optional): 샘플에 적용될 Optional transform.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df['img_path'].iloc[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "723d0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "train_path = os.path.join(path,\"train_folder\")\n",
    "val_path = os.path.join(path,\"val_folder\")\n",
    "test_path = os.path.join(path,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcef936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 및 데이터로더 준비\n",
    "# 이미지 전처리 및 임베딩\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n",
    "])\n",
    "\n",
    "transforms_val = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_path, transforms_train)\n",
    "val_dataset = datasets.ImageFolder(val_path, transforms_val)\n",
    "test_dataset = datasets.ImageFolder(test_path, transforms_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d5d65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train epoch: 0 ]\n",
      "Train accuarcy: 78.1094527363184\n",
      "Train average loss: 0.023701516549978683\n",
      "[ Validation epoch: 1 ]\n",
      "Accuarcy: 100.0\n",
      "Average loss: 0.05501251916090647\n",
      "Model saved! (time elapsed: 4.493528366088867)\n",
      "[ Train epoch: 1 ]\n",
      "Train accuarcy: 99.50248756218906\n",
      "Train average loss: 0.022245697714203032\n",
      "[ Validation epoch: 2 ]\n",
      "Accuarcy: 100.0\n",
      "Average loss: 0.04975422223409017\n",
      "Model saved! (time elapsed: 7.2047834396362305)\n",
      "[ Train epoch: 2 ]\n",
      "Train accuarcy: 100.0\n",
      "Train average loss: 0.01965516864956908\n",
      "[ Validation epoch: 3 ]\n",
      "Accuarcy: 100.0\n",
      "Average loss: 0.04171905914942423\n",
      "Model saved! (time elapsed: 9.845531463623047)\n",
      "[ Train epoch: 3 ]\n",
      "Train accuarcy: 100.0\n",
      "Train average loss: 0.01648885545445912\n",
      "[ Validation epoch: 4 ]\n",
      "Accuarcy: 100.0\n",
      "Average loss: 0.027362192670504253\n",
      "Model saved! (time elapsed: 12.446391820907593)\n",
      "[ Train epoch: 4 ]\n",
      "Train accuarcy: 100.0\n",
      "Train average loss: 0.010287872223711726\n",
      "[ Validation epoch: 5 ]\n",
      "Accuarcy: 100.0\n",
      "Average loss: 0.008057402446866035\n",
      "Model saved! (time elapsed: 15.139720678329468)\n",
      "[ Train epoch: 5 ]\n",
      "Train accuarcy: 100.0\n",
      "Train average loss: 0.007460559259599714\n",
      "[ Validation epoch: 6 ]\n",
      "Accuarcy: 100.0\n",
      "Average loss: 0.0008703987890233597\n",
      "Model saved! (time elapsed: 17.883832693099976)\n",
      "[ Train epoch: 6 ]\n",
      "Train accuarcy: 100.0\n",
      "Train average loss: 0.005348743342641574\n",
      "[ Validation epoch: 7 ]\n",
      "Accuarcy: 100.0\n",
      "Average loss: 0.00011019890856308241\n",
      "Model saved! (time elapsed: 20.566638469696045)\n",
      "[ Train epoch: 7 ]\n",
      "Train accuarcy: 100.0\n",
      "Train average loss: 0.005142170213051697\n",
      "[ Validation epoch: 8 ]\n",
      "Accuarcy: 100.0\n",
      "Average loss: 2.8625002111463498e-05\n",
      "Model saved! (time elapsed: 23.345548152923584)\n",
      "[ Train epoch: 8 ]\n",
      "Train accuarcy: 100.0\n",
      "Train average loss: 0.005945462789108504\n",
      "[ Validation epoch: 9 ]\n",
      "Accuarcy: 100.0\n",
      "Average loss: 1.342067844234407e-05\n",
      "Model saved! (time elapsed: 26.04659414291382)\n",
      "[ Train epoch: 9 ]\n",
      "Train accuarcy: 100.0\n",
      "Train average loss: 0.006313879024330064\n",
      "[ Validation epoch: 10 ]\n",
      "Accuarcy: 100.0\n",
      "Average loss: 8.995652630498322e-06\n",
      "Model saved! (time elapsed: 28.7266526222229)\n"
     ]
    }
   ],
   "source": [
    "# 모델, 손실 함수, 최적화기 초기화\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "file_name = \"AlexNet.pt\"\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "torch.cuda.manual_seed(42)\n",
    "net = AlexNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
    "\n",
    "train_result = []\n",
    "val_result = []\n",
    "\n",
    "start_time = time.time() # 시작 시간\n",
    "for i in range(num_epochs):\n",
    "    train_acc, train_loss = train(net, i, optimizer, criterion, train_dataloader) # 학습(training)\n",
    "    val_acc, val_loss = validate(net, i + 1, val_dataloader) # 검증(validation)\n",
    "\n",
    "    # 학습된 모델 저장하기\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print(f'Model saved! (time elapsed: {time.time() - start_time})')\n",
    "\n",
    "    # 현재 epoch에서의 정확도(accuracy)와 손실(loss) 값 저장하기\n",
    "    train_result.append((train_acc, train_loss))\n",
    "    val_result.append((val_acc, val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "612e2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터로 평가\n",
    "test_pred = []\n",
    "threshold = 0.99\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = net(inputs) # 모델 입력하여 결과 계산\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        max_probability, _ = torch.max(probabilities, dim=1)\n",
    "for prob in max_probability:\n",
    "    if prob < threshold:\n",
    "        test_pred.append(1)\n",
    "    else:\n",
    "        test_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37eca389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0590f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  label\n",
       "0  TEST_000      0\n",
       "1  TEST_001      0\n",
       "2  TEST_002      0\n",
       "3  TEST_003      0\n",
       "4  TEST_004      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['label'] = test_pred\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dbac0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./save/submit11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e70bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
