{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cb3af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\preparation\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b32a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "save_path = os.path.join(path,\"save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b57d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(1016) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192f4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩 클래스 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): csv 파일의 경로.\n",
    "            transform (callable, optional): 샘플에 적용될 Optional transform.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df['img_path'].iloc[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58889a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 이미지 전처리 및 임베딩\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomGrayscale(p=0.25),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_data = CustomDataset(csv_file=os.path.join(path,\"train.csv\"), transform=transform_train)\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c1a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 기반 Autoencoder 모델 정의\n",
    "class AutoencoderCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoencoderCNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.15),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ELU(0.15),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.15),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ELU(0.15),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ELU(0.15),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(0.15),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ELU(0.15),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069bc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoencoderCNN(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.15)\n",
      "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ELU(alpha=0.15)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.15)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ELU(alpha=0.15)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (1): ELU(alpha=0.15)\n",
      "    (2): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.15)\n",
      "    (4): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (5): ELU(alpha=0.15)\n",
      "    (6): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "Epoch [1/2000], Loss: 0.8819977920939664\n",
      "Epoch [2/2000], Loss: 0.8328058630088125\n",
      "Epoch [3/2000], Loss: 0.6093466136377182\n",
      "Epoch [4/2000], Loss: 0.43991877607336627\n",
      "Epoch [5/2000], Loss: 0.3883449738853974\n",
      "Epoch [6/2000], Loss: 0.36266121757981923\n",
      "Epoch [7/2000], Loss: 0.34090816414971864\n",
      "Epoch [8/2000], Loss: 0.32016768156082975\n",
      "Epoch [9/2000], Loss: 0.29713714360631127\n",
      "Epoch [10/2000], Loss: 0.27223279974270315\n",
      "Epoch [11/2000], Loss: 0.24848383832985246\n",
      "Epoch [12/2000], Loss: 0.2310920757167216\n",
      "Epoch [13/2000], Loss: 0.2151871895846067\n",
      "Epoch [14/2000], Loss: 0.20196438633220296\n",
      "Epoch [15/2000], Loss: 0.18892057589801825\n",
      "Epoch [16/2000], Loss: 0.1825950221276619\n",
      "Epoch [17/2000], Loss: 0.1750431949963592\n",
      "Epoch [18/2000], Loss: 0.17194791473972965\n",
      "Epoch [19/2000], Loss: 0.17017077546164464\n",
      "Epoch [20/2000], Loss: 0.16372411064978495\n",
      "Epoch [21/2000], Loss: 0.1635509812635995\n",
      "Epoch [22/2000], Loss: 0.16117924654707663\n",
      "Epoch [23/2000], Loss: 0.15953390915908724\n",
      "Epoch [24/2000], Loss: 0.15783293335370616\n",
      "Epoch [25/2000], Loss: 0.156355007643431\n",
      "Epoch [26/2000], Loss: 0.15521773451090978\n",
      "Epoch [27/2000], Loss: 0.1528617673216851\n",
      "Epoch [28/2000], Loss: 0.1522960771277477\n",
      "Epoch [29/2000], Loss: 0.14905343418110145\n",
      "Epoch [30/2000], Loss: 0.15100970388578136\n",
      "Epoch [31/2000], Loss: 0.14671672348964943\n",
      "Epoch [32/2000], Loss: 0.14681438618982343\n",
      "Epoch [33/2000], Loss: 0.14475816719129053\n",
      "Epoch [34/2000], Loss: 0.14627642537786367\n",
      "Epoch [35/2000], Loss: 0.14724452926519332\n",
      "Epoch [36/2000], Loss: 0.14340346897711775\n",
      "Epoch [37/2000], Loss: 0.1435586537273837\n",
      "Epoch [38/2000], Loss: 0.14242214950877177\n",
      "Epoch [39/2000], Loss: 0.14232862044667974\n",
      "Epoch [40/2000], Loss: 0.1401526857989495\n",
      "Epoch [41/2000], Loss: 0.14054226882301027\n",
      "Epoch [42/2000], Loss: 0.14078788969998068\n",
      "Epoch [43/2000], Loss: 0.14100564785406622\n",
      "Epoch [44/2000], Loss: 0.13739471956038138\n",
      "Epoch [45/2000], Loss: 0.13652992479398218\n",
      "Epoch [46/2000], Loss: 0.1360941231950348\n",
      "Epoch [47/2000], Loss: 0.13463916304245802\n",
      "Epoch [48/2000], Loss: 0.13507133603375843\n",
      "Epoch [49/2000], Loss: 0.13357711167122838\n",
      "Epoch [50/2000], Loss: 0.1322962829204792\n",
      "Epoch [51/2000], Loss: 0.1351938352618419\n",
      "Epoch [52/2000], Loss: 0.1315148089413352\n",
      "Epoch [53/2000], Loss: 0.13203187825534266\n",
      "Epoch [54/2000], Loss: 0.1298860554264185\n",
      "Epoch [55/2000], Loss: 0.1292143527750678\n",
      "Epoch [56/2000], Loss: 0.12784749087593364\n",
      "Epoch [57/2000], Loss: 0.12706206564052563\n",
      "Epoch [58/2000], Loss: 0.12940823619074665\n",
      "Epoch [59/2000], Loss: 0.12771146517124535\n",
      "Epoch [60/2000], Loss: 0.1282916182363537\n",
      "Epoch [61/2000], Loss: 0.12723812149584013\n",
      "Epoch [62/2000], Loss: 0.12456667633123801\n",
      "Epoch [63/2000], Loss: 0.1228439449704309\n",
      "Epoch [64/2000], Loss: 0.12301814276287813\n",
      "Epoch [65/2000], Loss: 0.12126562447055404\n",
      "Epoch [66/2000], Loss: 0.12093938005642152\n",
      "Epoch [67/2000], Loss: 0.12031025537442713\n",
      "Epoch [68/2000], Loss: 0.1191253254950886\n",
      "Epoch [69/2000], Loss: 0.1174674155146863\n",
      "Epoch [70/2000], Loss: 0.11664546312580645\n",
      "Epoch [71/2000], Loss: 0.11664656220887189\n",
      "Epoch [72/2000], Loss: 0.11746073874509391\n",
      "Epoch [73/2000], Loss: 0.11539991343385177\n",
      "Epoch [74/2000], Loss: 0.11447539477840836\n",
      "Epoch [75/2000], Loss: 0.11453529240939539\n",
      "Epoch [76/2000], Loss: 0.11368311095125798\n",
      "Epoch [77/2000], Loss: 0.11421795623123365\n",
      "Epoch [78/2000], Loss: 0.11341698712586237\n",
      "Epoch [79/2000], Loss: 0.11244950471489643\n",
      "Epoch [80/2000], Loss: 0.11231852231870794\n",
      "Epoch [81/2000], Loss: 0.11101438948106318\n",
      "Epoch [82/2000], Loss: 0.11085273920090545\n",
      "Epoch [83/2000], Loss: 0.11093976236704929\n",
      "Epoch [84/2000], Loss: 0.11086866207106012\n",
      "Epoch [85/2000], Loss: 0.11032039066995254\n",
      "Epoch [86/2000], Loss: 0.10971052101660222\n",
      "Epoch [87/2000], Loss: 0.10948645571867625\n",
      "Epoch [88/2000], Loss: 0.10890363062351523\n",
      "Epoch [89/2000], Loss: 0.10825290530920029\n",
      "Epoch [90/2000], Loss: 0.10808039820390128\n",
      "Epoch [91/2000], Loss: 0.10841204358938154\n",
      "Epoch [92/2000], Loss: 0.1078324641839999\n",
      "Epoch [93/2000], Loss: 0.10805511537572028\n",
      "Epoch [94/2000], Loss: 0.10738000927816534\n",
      "Epoch [95/2000], Loss: 0.10760745696478606\n",
      "Epoch [96/2000], Loss: 0.10593882997131124\n",
      "Epoch [97/2000], Loss: 0.10643778146712433\n",
      "Epoch [98/2000], Loss: 0.10542077245846601\n",
      "Epoch [99/2000], Loss: 0.10659663564582386\n",
      "Epoch [100/2000], Loss: 0.10604786365664622\n",
      "Epoch [101/2000], Loss: 0.10533401233629441\n",
      "Epoch [102/2000], Loss: 0.1051357120205539\n",
      "Epoch [103/2000], Loss: 0.10493720987453148\n",
      "Epoch [104/2000], Loss: 0.10466292122719993\n",
      "Epoch [105/2000], Loss: 0.10470074481667488\n",
      "Epoch [106/2000], Loss: 0.10392398219293272\n",
      "Epoch [107/2000], Loss: 0.10424587319434529\n",
      "Epoch [108/2000], Loss: 0.10393207663661437\n",
      "Epoch [109/2000], Loss: 0.10425697655325204\n",
      "Epoch [110/2000], Loss: 0.103557036201439\n",
      "Epoch [111/2000], Loss: 0.10305862422560302\n",
      "Epoch [112/2000], Loss: 0.10378553221623103\n",
      "Epoch [113/2000], Loss: 0.10311286718073026\n",
      "Epoch [114/2000], Loss: 0.10298918904692914\n",
      "Epoch [115/2000], Loss: 0.10259680477946018\n",
      "Epoch [116/2000], Loss: 0.1027593636806582\n",
      "Epoch [117/2000], Loss: 0.10322910452812491\n",
      "Epoch [118/2000], Loss: 0.1025143217452815\n",
      "Epoch [119/2000], Loss: 0.10222406220128279\n",
      "Epoch [120/2000], Loss: 0.101752091321587\n",
      "Epoch [121/2000], Loss: 0.10157924894016114\n",
      "Epoch [122/2000], Loss: 0.1021207514713068\n",
      "Epoch [123/2000], Loss: 0.10167814196555268\n",
      "Epoch [124/2000], Loss: 0.10188748505613614\n",
      "Epoch [125/2000], Loss: 0.10172678481245265\n",
      "Epoch [126/2000], Loss: 0.10102078434027417\n",
      "Epoch [127/2000], Loss: 0.10067908931086321\n",
      "Epoch [128/2000], Loss: 0.10113885550991471\n",
      "Epoch [129/2000], Loss: 0.10089848270998314\n",
      "Epoch [130/2000], Loss: 0.10089893205344957\n",
      "Epoch [131/2000], Loss: 0.10099349629151429\n",
      "Epoch [132/2000], Loss: 0.09983257718489204\n",
      "Epoch [133/2000], Loss: 0.10049068455544996\n",
      "Epoch [134/2000], Loss: 0.09997787630893815\n",
      "Epoch [135/2000], Loss: 0.10012862054814756\n",
      "Epoch [136/2000], Loss: 0.09983103592910678\n",
      "Epoch [137/2000], Loss: 0.1001519896964512\n",
      "Epoch [138/2000], Loss: 0.10001367281580195\n",
      "Epoch [139/2000], Loss: 0.09986454391843276\n",
      "Epoch [140/2000], Loss: 0.09964252735527468\n",
      "Epoch [141/2000], Loss: 0.10012621869783446\n",
      "Epoch [142/2000], Loss: 0.09963112985584098\n",
      "Epoch [143/2000], Loss: 0.09965780520802932\n",
      "Epoch [144/2000], Loss: 0.09896418886005598\n",
      "Epoch [145/2000], Loss: 0.09952432046613782\n",
      "Epoch [146/2000], Loss: 0.09917591438746788\n",
      "Epoch [147/2000], Loss: 0.09935770802934404\n",
      "Epoch [148/2000], Loss: 0.09875404065203779\n",
      "Epoch [149/2000], Loss: 0.09873685580044285\n",
      "Epoch [150/2000], Loss: 0.09875457174201527\n",
      "Epoch [151/2000], Loss: 0.09858895474476434\n",
      "Epoch [152/2000], Loss: 0.09859343653133777\n",
      "Epoch [153/2000], Loss: 0.09882446116125079\n",
      "Epoch [154/2000], Loss: 0.09816348556201783\n",
      "Epoch [155/2000], Loss: 0.09840849419714699\n",
      "Epoch [156/2000], Loss: 0.09865499455744112\n",
      "Epoch [157/2000], Loss: 0.09847853843455023\n",
      "Epoch [158/2000], Loss: 0.09835527669376051\n",
      "Epoch [159/2000], Loss: 0.09757621453401628\n",
      "Epoch [160/2000], Loss: 0.09777706046479409\n",
      "Epoch [161/2000], Loss: 0.09764210358611855\n",
      "Epoch [162/2000], Loss: 0.09748657369557681\n",
      "Epoch [163/2000], Loss: 0.0975542019510493\n",
      "Epoch [164/2000], Loss: 0.09756985681017799\n",
      "Epoch [165/2000], Loss: 0.0976085954918548\n",
      "Epoch [166/2000], Loss: 0.09750016386939886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [167/2000], Loss: 0.09741005444890456\n",
      "Epoch [168/2000], Loss: 0.09707020677870988\n",
      "Epoch [169/2000], Loss: 0.09718841790033618\n",
      "Epoch [170/2000], Loss: 0.09733865763379934\n",
      "Epoch [171/2000], Loss: 0.09693750812554024\n",
      "Epoch [172/2000], Loss: 0.09692855466139709\n",
      "Epoch [173/2000], Loss: 0.09684365424611759\n",
      "Epoch [174/2000], Loss: 0.09696231478116882\n",
      "Epoch [175/2000], Loss: 0.09672976225754465\n",
      "Epoch [176/2000], Loss: 0.09670452878508769\n",
      "Epoch [177/2000], Loss: 0.09679889210233106\n",
      "Epoch [178/2000], Loss: 0.09635624142599777\n",
      "Epoch [179/2000], Loss: 0.09706598929536174\n",
      "Epoch [180/2000], Loss: 0.09677397407276529\n",
      "Epoch [181/2000], Loss: 0.09635290262145056\n",
      "Epoch [182/2000], Loss: 0.09662903848808137\n",
      "Epoch [183/2000], Loss: 0.09645627939225362\n",
      "Epoch [184/2000], Loss: 0.09670004427013262\n",
      "Epoch [185/2000], Loss: 0.09657087747199994\n",
      "Epoch [186/2000], Loss: 0.09594063849096567\n",
      "Epoch [187/2000], Loss: 0.09651745086264722\n",
      "Epoch [188/2000], Loss: 0.09636742967954824\n",
      "Epoch [189/2000], Loss: 0.09625653198487322\n",
      "Epoch [190/2000], Loss: 0.09589823415861443\n",
      "Epoch [191/2000], Loss: 0.09620854594338109\n",
      "Epoch [192/2000], Loss: 0.09627024252230013\n",
      "Epoch [193/2000], Loss: 0.09578532158908709\n",
      "Epoch [194/2000], Loss: 0.09604458934124646\n",
      "Epoch [195/2000], Loss: 0.09578737280738185\n",
      "Epoch [196/2000], Loss: 0.09577560172954076\n",
      "Epoch [197/2000], Loss: 0.09570216702323564\n",
      "Epoch [198/2000], Loss: 0.09572380693725577\n",
      "Epoch [199/2000], Loss: 0.0953197043056779\n",
      "Epoch [200/2000], Loss: 0.09542881616964027\n",
      "Epoch [201/2000], Loss: 0.09552933338662269\n",
      "Epoch [202/2000], Loss: 0.09588258884882143\n",
      "Epoch [203/2000], Loss: 0.09561578960905612\n",
      "Epoch [204/2000], Loss: 0.0950306602207148\n",
      "Epoch [205/2000], Loss: 0.09527597317533314\n",
      "Epoch [206/2000], Loss: 0.09539114718845752\n",
      "Epoch [207/2000], Loss: 0.09522602150977498\n",
      "Epoch [208/2000], Loss: 0.0953077442699195\n",
      "Epoch [209/2000], Loss: 0.09524302111125328\n",
      "Epoch [210/2000], Loss: 0.09515164974429798\n",
      "Epoch [211/2000], Loss: 0.09497438339700162\n",
      "Epoch [212/2000], Loss: 0.09525772890714412\n",
      "Epoch [213/2000], Loss: 0.09477047261917534\n",
      "Epoch [214/2000], Loss: 0.09511101564191317\n",
      "Epoch [215/2000], Loss: 0.09482156856099205\n",
      "Epoch [216/2000], Loss: 0.09483210850909282\n",
      "Epoch [217/2000], Loss: 0.09466106217232109\n",
      "Epoch [218/2000], Loss: 0.09480643503262963\n",
      "Epoch [219/2000], Loss: 0.09476140312885455\n",
      "Epoch [220/2000], Loss: 0.09459780618338517\n",
      "Epoch [221/2000], Loss: 0.0946004996557191\n",
      "Epoch [222/2000], Loss: 0.09467520201010324\n",
      "Epoch [223/2000], Loss: 0.09464747616102998\n",
      "Epoch [224/2000], Loss: 0.09469778346063945\n",
      "Epoch [225/2000], Loss: 0.09472092150102758\n",
      "Epoch [226/2000], Loss: 0.09456382723341525\n",
      "Epoch [227/2000], Loss: 0.09485097740177817\n",
      "Epoch [228/2000], Loss: 0.09431280989742055\n",
      "Epoch [229/2000], Loss: 0.09454033163511696\n",
      "Epoch [230/2000], Loss: 0.09432989114047216\n",
      "Epoch [231/2000], Loss: 0.0944963921683495\n",
      "Epoch [232/2000], Loss: 0.09426595515488459\n",
      "Epoch [233/2000], Loss: 0.09403176969485663\n",
      "Epoch [234/2000], Loss: 0.09456228006613647\n",
      "Epoch [235/2000], Loss: 0.09442362297728588\n",
      "Epoch [236/2000], Loss: 0.09404861762629987\n",
      "Epoch [237/2000], Loss: 0.09419195721266975\n",
      "Epoch [238/2000], Loss: 0.09410465459728465\n",
      "Epoch [239/2000], Loss: 0.09433332991572053\n",
      "Epoch [240/2000], Loss: 0.09433504543813741\n",
      "Epoch [241/2000], Loss: 0.09386179232401468\n",
      "Epoch [242/2000], Loss: 0.09409667362629527\n",
      "Epoch [243/2000], Loss: 0.09405993225988647\n",
      "Epoch [244/2000], Loss: 0.0939252354519468\n",
      "Epoch [245/2000], Loss: 0.09376596449546411\n",
      "Epoch [246/2000], Loss: 0.09388586651411415\n",
      "Epoch [247/2000], Loss: 0.09382195438437618\n",
      "Epoch [248/2000], Loss: 0.09370429596990487\n",
      "Epoch [249/2000], Loss: 0.09382516834797434\n",
      "Epoch [250/2000], Loss: 0.09376507304923636\n",
      "Epoch [251/2000], Loss: 0.09390292904326614\n",
      "Epoch [252/2000], Loss: 0.09350974864803009\n",
      "Epoch [253/2000], Loss: 0.09383013896958929\n",
      "Epoch [254/2000], Loss: 0.09360416132099751\n",
      "Epoch [255/2000], Loss: 0.09350097032499985\n",
      "Epoch [256/2000], Loss: 0.09349209220616471\n",
      "Epoch [257/2000], Loss: 0.09366643012549396\n",
      "Epoch [258/2000], Loss: 0.09349292299837014\n",
      "Epoch [259/2000], Loss: 0.09341919925850882\n",
      "Epoch [260/2000], Loss: 0.09327696760495503\n",
      "Epoch [261/2000], Loss: 0.09329345542500277\n",
      "Epoch [262/2000], Loss: 0.09326957260638895\n",
      "Epoch [263/2000], Loss: 0.09337207220249892\n",
      "Epoch [264/2000], Loss: 0.09340039413299919\n",
      "Epoch [265/2000], Loss: 0.09338925009322278\n",
      "Epoch [266/2000], Loss: 0.09331798203674281\n",
      "Epoch [267/2000], Loss: 0.09328833330824901\n",
      "Epoch [268/2000], Loss: 0.09325237057998147\n",
      "Epoch [269/2000], Loss: 0.09305834231522161\n",
      "Epoch [270/2000], Loss: 0.09352138554546195\n",
      "Epoch [271/2000], Loss: 0.09328210507760025\n",
      "Epoch [272/2000], Loss: 0.0927848529437898\n",
      "Epoch [273/2000], Loss: 0.09281745769888022\n",
      "Epoch [274/2000], Loss: 0.09291347927750557\n",
      "Epoch [275/2000], Loss: 0.09336417024963899\n",
      "Epoch [276/2000], Loss: 0.09293434985786536\n",
      "Epoch [277/2000], Loss: 0.092960526755718\n",
      "Epoch [278/2000], Loss: 0.09286547494186483\n",
      "Epoch [279/2000], Loss: 0.0930678129476001\n",
      "Epoch [280/2000], Loss: 0.09308490566384624\n",
      "Epoch [281/2000], Loss: 0.09298210097870356\n",
      "Epoch [282/2000], Loss: 0.0929179568665688\n",
      "Epoch [283/2000], Loss: 0.09314226936286604\n",
      "Epoch [284/2000], Loss: 0.09271798828538035\n",
      "Epoch [285/2000], Loss: 0.09298781413987209\n",
      "Epoch [286/2000], Loss: 0.09279248097413023\n",
      "Epoch [287/2000], Loss: 0.0929133707019085\n",
      "Epoch [288/2000], Loss: 0.09291346479609539\n",
      "Epoch [289/2000], Loss: 0.09272889390657765\n",
      "Epoch [290/2000], Loss: 0.09243394462435459\n",
      "Epoch [291/2000], Loss: 0.09257469235311651\n",
      "Epoch [292/2000], Loss: 0.09250865582848938\n",
      "Epoch [293/2000], Loss: 0.09269373692537138\n",
      "Epoch [294/2000], Loss: 0.09249137219548785\n",
      "Epoch [295/2000], Loss: 0.09256241582508938\n",
      "Epoch [296/2000], Loss: 0.09270197198564457\n",
      "Epoch [297/2000], Loss: 0.09267702873603839\n",
      "Epoch [298/2000], Loss: 0.09266688422837728\n",
      "Epoch [299/2000], Loss: 0.09259070123725094\n",
      "Epoch [300/2000], Loss: 0.09250433445676391\n",
      "Epoch [301/2000], Loss: 0.09250301301059588\n",
      "Epoch [302/2000], Loss: 0.09239162280805793\n",
      "Epoch [303/2000], Loss: 0.09273840263136116\n",
      "Epoch [304/2000], Loss: 0.09252551299445506\n",
      "Epoch [305/2000], Loss: 0.09240125462482793\n",
      "Epoch [306/2000], Loss: 0.0922457733204667\n",
      "Epoch [307/2000], Loss: 0.09264594816685842\n",
      "Epoch [308/2000], Loss: 0.09206423271849681\n",
      "Epoch [309/2000], Loss: 0.09227380485321994\n",
      "Epoch [310/2000], Loss: 0.09221399260658614\n",
      "Epoch [311/2000], Loss: 0.09234740490644751\n",
      "Epoch [312/2000], Loss: 0.09221473546095298\n",
      "Epoch [313/2000], Loss: 0.09256970273776793\n",
      "Epoch [314/2000], Loss: 0.09215708825509873\n",
      "Epoch [315/2000], Loss: 0.09205033902970838\n",
      "Epoch [316/2000], Loss: 0.092348430323209\n",
      "Epoch [317/2000], Loss: 0.09218366034853627\n",
      "Epoch [318/2000], Loss: 0.09221326727682436\n",
      "Epoch [319/2000], Loss: 0.09225191270381632\n",
      "Epoch [320/2000], Loss: 0.09211122930189813\n",
      "Epoch [321/2000], Loss: 0.09227369159040316\n",
      "Epoch [322/2000], Loss: 0.09175932585773333\n",
      "Epoch [323/2000], Loss: 0.09210223431738329\n",
      "Epoch [324/2000], Loss: 0.09230134356329699\n",
      "Epoch [325/2000], Loss: 0.09228776549229599\n",
      "Epoch [326/2000], Loss: 0.09211968889398754\n",
      "Epoch [327/2000], Loss: 0.09205094843823025\n",
      "Epoch [328/2000], Loss: 0.09221346207627668\n",
      "Epoch [329/2000], Loss: 0.09182238393406353\n",
      "Epoch [330/2000], Loss: 0.09226562918771601\n",
      "Epoch [331/2000], Loss: 0.09190799183968647\n",
      "Epoch [332/2000], Loss: 0.09178450252388565\n",
      "Epoch [333/2000], Loss: 0.09202554797482602\n",
      "Epoch [334/2000], Loss: 0.09214313702544136\n",
      "Epoch [335/2000], Loss: 0.09199329797930561\n",
      "Epoch [336/2000], Loss: 0.09182534646680098\n",
      "Epoch [337/2000], Loss: 0.09176013314388168\n",
      "Epoch [338/2000], Loss: 0.0919033600970613\n",
      "Epoch [339/2000], Loss: 0.09155224036302925\n",
      "Epoch [340/2000], Loss: 0.09196600317955017\n",
      "Epoch [341/2000], Loss: 0.09184838366200666\n",
      "Epoch [342/2000], Loss: 0.09168908815008933\n",
      "Epoch [343/2000], Loss: 0.09148544352938871\n",
      "Epoch [344/2000], Loss: 0.09160914265074081\n",
      "Epoch [345/2000], Loss: 0.09173871660736245\n",
      "Epoch [346/2000], Loss: 0.09182358830467637\n",
      "Epoch [347/2000], Loss: 0.09177866913902928\n",
      "Epoch [348/2000], Loss: 0.09178037077468326\n",
      "Epoch [349/2000], Loss: 0.09154103622889855\n",
      "Epoch [350/2000], Loss: 0.09152707821326636\n",
      "Epoch [351/2000], Loss: 0.09149105616018806\n",
      "Epoch [352/2000], Loss: 0.09159186440454402\n",
      "Epoch [353/2000], Loss: 0.09160948184454384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [354/2000], Loss: 0.09155786551640067\n",
      "Epoch [355/2000], Loss: 0.0914742002884547\n",
      "Epoch [356/2000], Loss: 0.09163981273840291\n",
      "Epoch [357/2000], Loss: 0.09154427856066977\n",
      "Epoch [358/2000], Loss: 0.0915721715406073\n",
      "Epoch [359/2000], Loss: 0.09160528912650587\n",
      "Epoch [360/2000], Loss: 0.09134819708379781\n",
      "Epoch [361/2000], Loss: 0.09177089479047927\n",
      "Epoch [362/2000], Loss: 0.09124131916974072\n",
      "Epoch [363/2000], Loss: 0.09157726871715464\n",
      "Epoch [364/2000], Loss: 0.0913580166342113\n",
      "Epoch [365/2000], Loss: 0.0916394163885027\n",
      "Epoch [366/2000], Loss: 0.09112557265120493\n",
      "Epoch [367/2000], Loss: 0.09122988011495609\n",
      "Epoch [368/2000], Loss: 0.09116918852491558\n",
      "Epoch [369/2000], Loss: 0.09100993985021619\n",
      "Epoch [370/2000], Loss: 0.09153249471540183\n",
      "Epoch [371/2000], Loss: 0.09127599683026193\n",
      "Epoch [372/2000], Loss: 0.09133641152454654\n",
      "Epoch [373/2000], Loss: 0.09129368632752011\n",
      "Epoch [374/2000], Loss: 0.0912529082505356\n",
      "Epoch [375/2000], Loss: 0.09127000985151165\n",
      "Epoch [376/2000], Loss: 0.09134648313544726\n",
      "Epoch [377/2000], Loss: 0.091139544413683\n",
      "Epoch [378/2000], Loss: 0.09129079043025702\n",
      "Epoch [379/2000], Loss: 0.09121706550110115\n",
      "Epoch [380/2000], Loss: 0.09100143149705\n",
      "Epoch [381/2000], Loss: 0.0909863777213813\n",
      "Epoch [382/2000], Loss: 0.09123676172304601\n",
      "Epoch [383/2000], Loss: 0.09109097107055601\n",
      "Epoch [384/2000], Loss: 0.09111235283769913\n",
      "Epoch [385/2000], Loss: 0.09095754212057086\n",
      "Epoch [386/2000], Loss: 0.09130999015670427\n",
      "Epoch [387/2000], Loss: 0.09083956000810497\n",
      "Epoch [388/2000], Loss: 0.09122542253402477\n",
      "Epoch [389/2000], Loss: 0.09120414930749947\n",
      "Epoch [390/2000], Loss: 0.09107133676188653\n",
      "Epoch [391/2000], Loss: 0.09116730783047251\n",
      "Epoch [392/2000], Loss: 0.09096578711495153\n",
      "Epoch [393/2000], Loss: 0.09102910169413392\n",
      "Epoch [394/2000], Loss: 0.09094858309472671\n",
      "Epoch [395/2000], Loss: 0.09084913358442101\n",
      "Epoch [396/2000], Loss: 0.09099030722055076\n",
      "Epoch [397/2000], Loss: 0.09116926369532732\n",
      "Epoch [398/2000], Loss: 0.09096859776777841\n",
      "Epoch [399/2000], Loss: 0.09092691215411039\n",
      "Epoch [400/2000], Loss: 0.09100339956966365\n",
      "Epoch [401/2000], Loss: 0.09084326605981505\n",
      "Epoch [402/2000], Loss: 0.09098065221253696\n",
      "Epoch [403/2000], Loss: 0.09102538210545347\n",
      "Epoch [404/2000], Loss: 0.09098428207943697\n",
      "Epoch [405/2000], Loss: 0.09087367348827667\n",
      "Epoch [406/2000], Loss: 0.09112658883344399\n",
      "Epoch [407/2000], Loss: 0.09052083581825937\n",
      "Epoch [408/2000], Loss: 0.09114624416464372\n",
      "Epoch [409/2000], Loss: 0.09066369209630948\n",
      "Epoch [410/2000], Loss: 0.09109536411476807\n",
      "Epoch [411/2000], Loss: 0.09095366547505061\n",
      "Epoch [412/2000], Loss: 0.0909897890728964\n",
      "Epoch [413/2000], Loss: 0.09046287166540612\n",
      "Epoch [414/2000], Loss: 0.09064802093684954\n",
      "Epoch [415/2000], Loss: 0.09078481282706552\n",
      "Epoch [416/2000], Loss: 0.09084359224133648\n",
      "Epoch [417/2000], Loss: 0.09076698099923246\n",
      "Epoch [418/2000], Loss: 0.09095604116088347\n",
      "Epoch [419/2000], Loss: 0.09059820198257204\n",
      "Epoch [420/2000], Loss: 0.09064935077803796\n",
      "Epoch [421/2000], Loss: 0.09033424120413865\n",
      "Epoch [422/2000], Loss: 0.09091142155754735\n",
      "Epoch [423/2000], Loss: 0.09062673595729569\n",
      "Epoch [424/2000], Loss: 0.09079691648763111\n",
      "Epoch [425/2000], Loss: 0.09049610317872724\n",
      "Epoch [426/2000], Loss: 0.09061993375210695\n",
      "Epoch [427/2000], Loss: 0.0905741973312248\n",
      "Epoch [428/2000], Loss: 0.09062265748149352\n",
      "Epoch [429/2000], Loss: 0.0906531285022346\n",
      "Epoch [430/2000], Loss: 0.09071318476412778\n",
      "Epoch [431/2000], Loss: 0.09074186369287016\n",
      "Epoch [432/2000], Loss: 0.09059449026422321\n",
      "Epoch [433/2000], Loss: 0.09046000805399228\n",
      "Epoch [434/2000], Loss: 0.09050241287605304\n",
      "Epoch [435/2000], Loss: 0.09058156053365117\n",
      "Epoch [436/2000], Loss: 0.09065952330407961\n",
      "Epoch [437/2000], Loss: 0.09043194360576325\n",
      "Epoch [438/2000], Loss: 0.09034642136432755\n",
      "Epoch [439/2000], Loss: 0.09072584693840412\n",
      "Epoch [440/2000], Loss: 0.09032248145957508\n",
      "Epoch [441/2000], Loss: 0.09046349230226776\n",
      "Epoch [442/2000], Loss: 0.09049281268052652\n",
      "Epoch [443/2000], Loss: 0.09062273408605459\n",
      "Epoch [444/2000], Loss: 0.09049877419438161\n",
      "Epoch [445/2000], Loss: 0.0904022078488914\n",
      "Epoch [446/2000], Loss: 0.09041844213932333\n",
      "Epoch [447/2000], Loss: 0.0906671436389847\n",
      "Epoch [448/2000], Loss: 0.0905031832590909\n",
      "Epoch [449/2000], Loss: 0.0902947723305841\n",
      "Epoch [450/2000], Loss: 0.09022979221433541\n",
      "Epoch [451/2000], Loss: 0.09027169620347135\n",
      "Epoch [452/2000], Loss: 0.09025689889567559\n",
      "Epoch [453/2000], Loss: 0.09050965707906534\n",
      "Epoch [454/2000], Loss: 0.09035623409378697\n",
      "Epoch [455/2000], Loss: 0.09014934007550629\n",
      "Epoch [456/2000], Loss: 0.09039919410652958\n",
      "Epoch [457/2000], Loss: 0.09042069490806598\n",
      "Epoch [458/2000], Loss: 0.09010457446877386\n",
      "Epoch [459/2000], Loss: 0.09026060568194993\n",
      "Epoch [460/2000], Loss: 0.09019712540605258\n",
      "Epoch [461/2000], Loss: 0.09011910131699602\n",
      "Epoch [462/2000], Loss: 0.09006963372930114\n",
      "Epoch [463/2000], Loss: 0.09031813986984218\n",
      "Epoch [464/2000], Loss: 0.0904911027547899\n",
      "Epoch [465/2000], Loss: 0.09021768477601065\n",
      "Epoch [466/2000], Loss: 0.09020417589396938\n",
      "Epoch [467/2000], Loss: 0.09022974761578959\n",
      "Epoch [468/2000], Loss: 0.09020325009811653\n",
      "Epoch [469/2000], Loss: 0.09007259000075256\n",
      "Epoch [470/2000], Loss: 0.09007427138341985\n",
      "Epoch [471/2000], Loss: 0.09016915778039207\n",
      "Epoch [472/2000], Loss: 0.09024394957672262\n",
      "Epoch [473/2000], Loss: 0.09016079609522797\n",
      "Epoch [474/2000], Loss: 0.08989353254087654\n",
      "Epoch [475/2000], Loss: 0.09004554929028094\n",
      "Epoch [476/2000], Loss: 0.09029726050969021\n",
      "Epoch [477/2000], Loss: 0.09028949885860856\n",
      "Epoch [478/2000], Loss: 0.09006682639950318\n",
      "Epoch [479/2000], Loss: 0.09040536630041722\n",
      "Epoch [480/2000], Loss: 0.09020342495939541\n",
      "Epoch [481/2000], Loss: 0.09028423479605169\n",
      "Epoch [482/2000], Loss: 0.0903731633869695\n",
      "Epoch [483/2000], Loss: 0.09008370252422324\n",
      "Epoch [484/2000], Loss: 0.0899509791407227\n",
      "Epoch [485/2000], Loss: 0.09005761541810954\n",
      "Epoch [486/2000], Loss: 0.09001264843582547\n",
      "Epoch [487/2000], Loss: 0.08989422981727851\n",
      "Epoch [488/2000], Loss: 0.09019181541573833\n",
      "Epoch [489/2000], Loss: 0.08999571421056846\n",
      "Epoch [490/2000], Loss: 0.08994199181666397\n",
      "Epoch [491/2000], Loss: 0.09020800528252068\n",
      "Epoch [492/2000], Loss: 0.08973969064408065\n",
      "Epoch [493/2000], Loss: 0.090146262740865\n",
      "Epoch [494/2000], Loss: 0.09008630179743252\n",
      "Epoch [495/2000], Loss: 0.08980259068415199\n",
      "Epoch [496/2000], Loss: 0.08982798537597969\n",
      "Epoch [497/2000], Loss: 0.09002680184555725\n",
      "Epoch [498/2000], Loss: 0.09011061853366278\n",
      "Epoch [499/2000], Loss: 0.08980140981959625\n",
      "Epoch [500/2000], Loss: 0.0898591408357374\n",
      "Epoch [501/2000], Loss: 0.08994395271853102\n",
      "Epoch [502/2000], Loss: 0.08978047564695699\n",
      "Epoch [503/2000], Loss: 0.09003394118077318\n",
      "Epoch [504/2000], Loss: 0.08996441967330628\n",
      "Epoch [505/2000], Loss: 0.09000390761055298\n",
      "Epoch [506/2000], Loss: 0.0898213190302043\n",
      "Epoch [507/2000], Loss: 0.0899220755402471\n",
      "Epoch [508/2000], Loss: 0.08983213153663376\n",
      "Epoch [509/2000], Loss: 0.08984645246200158\n",
      "Epoch [510/2000], Loss: 0.08970369807851146\n",
      "Epoch [511/2000], Loss: 0.08983431123371975\n",
      "Epoch [512/2000], Loss: 0.08990919177241169\n",
      "Epoch [513/2000], Loss: 0.09000139106327379\n",
      "Epoch [514/2000], Loss: 0.08992201859402545\n",
      "Epoch [515/2000], Loss: 0.08993171050514974\n",
      "Epoch [516/2000], Loss: 0.08960179222021863\n",
      "Epoch [517/2000], Loss: 0.09008146738502341\n",
      "Epoch [518/2000], Loss: 0.08990218283984583\n",
      "Epoch [519/2000], Loss: 0.08969388143137587\n",
      "Epoch [520/2000], Loss: 0.08962538778921808\n",
      "Epoch [521/2000], Loss: 0.08977950007562906\n",
      "Epoch [522/2000], Loss: 0.08972355670912165\n",
      "Epoch [523/2000], Loss: 0.08988716638703861\n",
      "Epoch [524/2000], Loss: 0.0897608456057562\n",
      "Epoch [525/2000], Loss: 0.08946084822287582\n",
      "Epoch [526/2000], Loss: 0.08970644632835344\n",
      "Epoch [527/2000], Loss: 0.08978359485176247\n",
      "Epoch [528/2000], Loss: 0.08976710577246169\n",
      "Epoch [529/2000], Loss: 0.08971150569232976\n",
      "Epoch [530/2000], Loss: 0.08994437292428084\n",
      "Epoch [531/2000], Loss: 0.08986455016712627\n",
      "Epoch [532/2000], Loss: 0.08950637686700329\n",
      "Epoch [533/2000], Loss: 0.08942233130965434\n",
      "Epoch [534/2000], Loss: 0.08962990340072784\n",
      "Epoch [535/2000], Loss: 0.08997010988808574\n",
      "Epoch [536/2000], Loss: 0.08985017026674019\n",
      "Epoch [537/2000], Loss: 0.08969336821579597\n",
      "Epoch [538/2000], Loss: 0.08976262975746477\n",
      "Epoch [539/2000], Loss: 0.08942622631928171\n",
      "Epoch [540/2000], Loss: 0.0895132933494071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [541/2000], Loss: 0.08946916356053151\n",
      "Epoch [542/2000], Loss: 0.08972541704564027\n",
      "Epoch [543/2000], Loss: 0.08951305664481132\n",
      "Epoch [544/2000], Loss: 0.08967233844486201\n",
      "Epoch [545/2000], Loss: 0.08996994873867348\n",
      "Epoch [546/2000], Loss: 0.08965406717269074\n",
      "Epoch [547/2000], Loss: 0.08969391917398838\n",
      "Epoch [548/2000], Loss: 0.08960117039406243\n",
      "Epoch [549/2000], Loss: 0.0896704184337401\n",
      "Epoch [550/2000], Loss: 0.08974071147856018\n",
      "Epoch [551/2000], Loss: 0.08965173027884792\n",
      "Epoch [552/2000], Loss: 0.08965603482555336\n",
      "Epoch [553/2000], Loss: 0.08972379799599939\n",
      "Epoch [554/2000], Loss: 0.08949267815256343\n",
      "Epoch [555/2000], Loss: 0.08963195468898111\n",
      "Epoch [556/2000], Loss: 0.08942379249793263\n",
      "Epoch [557/2000], Loss: 0.08957222737197025\n",
      "Epoch [558/2000], Loss: 0.0897824237813972\n",
      "Epoch [559/2000], Loss: 0.08953076121812695\n",
      "Epoch [560/2000], Loss: 0.08952084788833985\n",
      "Epoch [561/2000], Loss: 0.08969399535879842\n",
      "Epoch [562/2000], Loss: 0.08946652234719953\n",
      "Epoch [563/2000], Loss: 0.0895346869745165\n",
      "Epoch [564/2000], Loss: 0.08948932052917884\n",
      "Epoch [565/2000], Loss: 0.08960485465369873\n",
      "Epoch [566/2000], Loss: 0.0895074735714796\n",
      "Epoch [567/2000], Loss: 0.08963006178677922\n",
      "Epoch [568/2000], Loss: 0.08934395581903593\n",
      "Epoch [569/2000], Loss: 0.08943912600267662\n",
      "Epoch [570/2000], Loss: 0.08946204073552234\n",
      "Epoch [571/2000], Loss: 0.0894527727029693\n",
      "Epoch [572/2000], Loss: 0.08929820348259429\n",
      "Epoch [573/2000], Loss: 0.08941711908634839\n",
      "Epoch [574/2000], Loss: 0.08924540118292464\n",
      "Epoch [575/2000], Loss: 0.08930209772267812\n",
      "Epoch [576/2000], Loss: 0.08963810781917661\n",
      "Epoch [577/2000], Loss: 0.08940916571398856\n",
      "Epoch [578/2000], Loss: 0.08937286176312138\n",
      "Epoch [579/2000], Loss: 0.08932284339213035\n",
      "Epoch [580/2000], Loss: 0.08929238828694877\n",
      "Epoch [581/2000], Loss: 0.08922735556190563\n",
      "Epoch [582/2000], Loss: 0.08936609320797272\n",
      "Epoch [583/2000], Loss: 0.08912056243755448\n",
      "Epoch [584/2000], Loss: 0.08935342792054297\n",
      "Epoch [585/2000], Loss: 0.08923549240044025\n",
      "Epoch [586/2000], Loss: 0.08934195385152745\n",
      "Epoch [587/2000], Loss: 0.08951066028624073\n",
      "Epoch [588/2000], Loss: 0.0892020979887443\n",
      "Epoch [589/2000], Loss: 0.08929122470214333\n",
      "Epoch [590/2000], Loss: 0.08916539898220922\n",
      "Epoch [591/2000], Loss: 0.0894157964508858\n",
      "Epoch [592/2000], Loss: 0.08928947402557856\n",
      "Epoch [593/2000], Loss: 0.08951124118667253\n",
      "Epoch [594/2000], Loss: 0.08927934406928613\n",
      "Epoch [595/2000], Loss: 0.08944516254702645\n",
      "Epoch [596/2000], Loss: 0.08951619606762425\n",
      "Epoch [597/2000], Loss: 0.0893021737325919\n",
      "Epoch [598/2000], Loss: 0.08950327732053721\n",
      "Epoch [599/2000], Loss: 0.0891951666751378\n",
      "Epoch [600/2000], Loss: 0.08930627900250081\n",
      "Epoch [601/2000], Loss: 0.08926436948664311\n",
      "Epoch [602/2000], Loss: 0.0893041247003515\n",
      "Epoch [603/2000], Loss: 0.08935551880530908\n",
      "Epoch [604/2000], Loss: 0.08933714315505095\n",
      "Epoch [605/2000], Loss: 0.08937848348852614\n",
      "Epoch [606/2000], Loss: 0.08937677978909632\n",
      "Epoch [607/2000], Loss: 0.08934977933974333\n",
      "Epoch [608/2000], Loss: 0.08944733440876007\n",
      "Epoch [609/2000], Loss: 0.08918713477435807\n",
      "Epoch [610/2000], Loss: 0.08932844591392598\n",
      "Epoch [611/2000], Loss: 0.08921538825046288\n",
      "Epoch [612/2000], Loss: 0.08910721946210369\n",
      "Epoch [613/2000], Loss: 0.08906549596590616\n",
      "Epoch [614/2000], Loss: 0.0891430366417052\n",
      "Epoch [615/2000], Loss: 0.0892939224069667\n",
      "Epoch [616/2000], Loss: 0.08934601018546333\n",
      "Epoch [617/2000], Loss: 0.0893253355938504\n",
      "Epoch [618/2000], Loss: 0.089199240708575\n",
      "Epoch [619/2000], Loss: 0.08910720928314146\n",
      "Epoch [620/2000], Loss: 0.0890544796003982\n",
      "Epoch [621/2000], Loss: 0.08931819020722394\n",
      "Epoch [622/2000], Loss: 0.08893073003896525\n",
      "Epoch [623/2000], Loss: 0.08935239760668624\n",
      "Epoch [624/2000], Loss: 0.08909537723646477\n",
      "Epoch [625/2000], Loss: 0.08902181866862964\n",
      "Epoch [626/2000], Loss: 0.08911529197379457\n",
      "Epoch [627/2000], Loss: 0.08889005151293088\n",
      "Epoch [628/2000], Loss: 0.08943532067985042\n",
      "Epoch [629/2000], Loss: 0.08888667164274225\n",
      "Epoch [630/2000], Loss: 0.08929418936861513\n",
      "Epoch [631/2000], Loss: 0.08912971759206252\n",
      "Epoch [632/2000], Loss: 0.08933796429298294\n",
      "Epoch [633/2000], Loss: 0.08917176688500973\n",
      "Epoch [634/2000], Loss: 0.0889185392101046\n",
      "Epoch [635/2000], Loss: 0.08910525436272644\n",
      "Epoch [636/2000], Loss: 0.08903270578580283\n",
      "Epoch [637/2000], Loss: 0.08907108806388479\n",
      "Epoch [638/2000], Loss: 0.08905299410154002\n",
      "Epoch [639/2000], Loss: 0.08885765205106824\n",
      "Epoch [640/2000], Loss: 0.08906393536659474\n",
      "Epoch [641/2000], Loss: 0.0892252030786774\n",
      "Epoch [642/2000], Loss: 0.08906303367144625\n",
      "Epoch [643/2000], Loss: 0.08896656295923\n",
      "Epoch [644/2000], Loss: 0.08893235660914524\n",
      "Epoch [645/2000], Loss: 0.08887904375231882\n",
      "Epoch [646/2000], Loss: 0.08924668152847201\n",
      "Epoch [647/2000], Loss: 0.08912900352561978\n",
      "Epoch [648/2000], Loss: 0.08907220582587058\n",
      "Epoch [649/2000], Loss: 0.08910478735473794\n",
      "Epoch [650/2000], Loss: 0.08907116379396457\n",
      "Epoch [651/2000], Loss: 0.08913869673097638\n",
      "Epoch [652/2000], Loss: 0.08919971471241382\n",
      "Epoch [653/2000], Loss: 0.08887870882598448\n",
      "Epoch [654/2000], Loss: 0.08888755070631493\n",
      "Epoch [655/2000], Loss: 0.08880719122752337\n",
      "Epoch [656/2000], Loss: 0.08887001480295065\n",
      "Epoch [657/2000], Loss: 0.08884538696125639\n",
      "Epoch [658/2000], Loss: 0.08908968702168532\n",
      "Epoch [659/2000], Loss: 0.08882828494052931\n",
      "Epoch [660/2000], Loss: 0.08886431367464469\n",
      "Epoch [661/2000], Loss: 0.0889406003092936\n",
      "Epoch [662/2000], Loss: 0.08907563417730197\n",
      "Epoch [663/2000], Loss: 0.08885097360247178\n",
      "Epoch [664/2000], Loss: 0.08920787274837494\n",
      "Epoch [665/2000], Loss: 0.0889009984096451\n",
      "Epoch [666/2000], Loss: 0.08890615001390798\n",
      "Epoch [667/2000], Loss: 0.08894347095153701\n",
      "Epoch [668/2000], Loss: 0.08890540726447889\n",
      "Epoch [669/2000], Loss: 0.08898737708307768\n",
      "Epoch [670/2000], Loss: 0.08874465742021659\n",
      "Epoch [671/2000], Loss: 0.08902994106073335\n",
      "Epoch [672/2000], Loss: 0.08885574876002862\n",
      "Epoch [673/2000], Loss: 0.08873463757860829\n",
      "Epoch [674/2000], Loss: 0.08879475942659826\n",
      "Epoch [675/2000], Loss: 0.08871077973518013\n",
      "Epoch [676/2000], Loss: 0.08888505238322585\n",
      "Epoch [677/2000], Loss: 0.08888769789900579\n",
      "Epoch [678/2000], Loss: 0.08875170448016673\n",
      "Epoch [679/2000], Loss: 0.08906407930621518\n",
      "Epoch [680/2000], Loss: 0.08891051741832859\n",
      "Epoch [681/2000], Loss: 0.08867997896503395\n",
      "Epoch [682/2000], Loss: 0.08905022934149129\n",
      "Epoch [683/2000], Loss: 0.08875830611432663\n",
      "Epoch [684/2000], Loss: 0.08916721709877112\n",
      "Epoch [685/2000], Loss: 0.08908790790698898\n",
      "Epoch [686/2000], Loss: 0.08898800471578965\n",
      "Epoch [687/2000], Loss: 0.08884245545511514\n",
      "Epoch [688/2000], Loss: 0.08885878772243087\n",
      "Epoch [689/2000], Loss: 0.08924971702792835\n",
      "Epoch [690/2000], Loss: 0.08859038559343893\n",
      "Epoch [691/2000], Loss: 0.08892675219847003\n",
      "Epoch [692/2000], Loss: 0.08856830455607652\n",
      "Epoch [693/2000], Loss: 0.08878534332687306\n",
      "Epoch [694/2000], Loss: 0.08871742589792735\n",
      "Epoch [695/2000], Loss: 0.08865927687972924\n",
      "Epoch [696/2000], Loss: 0.08895662073658106\n",
      "Epoch [697/2000], Loss: 0.08877500832220758\n",
      "Epoch [698/2000], Loss: 0.08879864730045829\n",
      "Epoch [699/2000], Loss: 0.08869751060092954\n",
      "Epoch [700/2000], Loss: 0.08860463470640317\n",
      "Epoch [701/2000], Loss: 0.08878012498219807\n",
      "Epoch [702/2000], Loss: 0.08867803271947332\n",
      "Epoch [703/2000], Loss: 0.08879934307275243\n",
      "Epoch [704/2000], Loss: 0.0888355447093086\n",
      "Epoch [705/2000], Loss: 0.08884030629491582\n",
      "Epoch [706/2000], Loss: 0.08872261052260376\n",
      "Epoch [707/2000], Loss: 0.08861909733271935\n",
      "Epoch [708/2000], Loss: 0.08872364776235231\n",
      "Epoch [709/2000], Loss: 0.08854231934452281\n",
      "Epoch [710/2000], Loss: 0.08890216000063318\n",
      "Epoch [711/2000], Loss: 0.0887431598535166\n",
      "Epoch [712/2000], Loss: 0.08889486336372268\n",
      "Epoch [713/2000], Loss: 0.08865237963591382\n",
      "Epoch [714/2000], Loss: 0.08858285564492006\n",
      "Epoch [715/2000], Loss: 0.08878099718983744\n",
      "Epoch [716/2000], Loss: 0.08883028120641977\n",
      "Epoch [717/2000], Loss: 0.08886117610573209\n",
      "Epoch [718/2000], Loss: 0.08857509343417037\n",
      "Epoch [719/2000], Loss: 0.08888568529780481\n",
      "Epoch [720/2000], Loss: 0.08849095283819476\n",
      "Epoch [721/2000], Loss: 0.08885626935623062\n",
      "Epoch [722/2000], Loss: 0.08849931539784014\n",
      "Epoch [723/2000], Loss: 0.08857082844899854\n",
      "Epoch [724/2000], Loss: 0.08843173471414986\n",
      "Epoch [725/2000], Loss: 0.088649961835062\n",
      "Epoch [726/2000], Loss: 0.08876731274693225\n",
      "Epoch [727/2000], Loss: 0.08860714002534258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [728/2000], Loss: 0.08874892681277415\n",
      "Epoch [729/2000], Loss: 0.08857035941221345\n",
      "Epoch [730/2000], Loss: 0.08867050728327791\n",
      "Epoch [731/2000], Loss: 0.08848554850883887\n",
      "Epoch [732/2000], Loss: 0.08866732434627596\n",
      "Epoch [733/2000], Loss: 0.08887405312257193\n",
      "Epoch [734/2000], Loss: 0.08850975467565474\n",
      "Epoch [735/2000], Loss: 0.08855516271132259\n",
      "Epoch [736/2000], Loss: 0.08851075193411867\n",
      "Epoch [737/2000], Loss: 0.0885446621148799\n",
      "Epoch [738/2000], Loss: 0.08863016392843265\n",
      "Epoch [739/2000], Loss: 0.08849280317064742\n",
      "Epoch [740/2000], Loss: 0.08876605615229674\n",
      "Epoch [741/2000], Loss: 0.08856319251334724\n",
      "Epoch [742/2000], Loss: 0.08844215122047165\n",
      "Epoch [743/2000], Loss: 0.08855264591918864\n",
      "Epoch [744/2000], Loss: 0.08853426502204277\n",
      "Epoch [745/2000], Loss: 0.08856525370072871\n",
      "Epoch [746/2000], Loss: 0.08854250753289657\n",
      "Epoch [747/2000], Loss: 0.08860612922990826\n",
      "Epoch [748/2000], Loss: 0.08865769368382127\n",
      "Epoch [749/2000], Loss: 0.08859621306680178\n",
      "Epoch [750/2000], Loss: 0.08860027405297813\n",
      "Epoch [751/2000], Loss: 0.08854143811223653\n",
      "Epoch [752/2000], Loss: 0.08852324152076749\n",
      "Epoch [753/2000], Loss: 0.08856411628040349\n",
      "Epoch [754/2000], Loss: 0.08879197637240092\n",
      "Epoch [755/2000], Loss: 0.08856810622371979\n",
      "Epoch [756/2000], Loss: 0.08863042420904402\n",
      "Epoch [757/2000], Loss: 0.08836467459168233\n",
      "Epoch [758/2000], Loss: 0.08851864073478\n",
      "Epoch [759/2000], Loss: 0.08870593094629861\n",
      "Epoch [760/2000], Loss: 0.08840054504468407\n",
      "Epoch [761/2000], Loss: 0.08847495588198515\n",
      "Epoch [762/2000], Loss: 0.08853997580462218\n",
      "Epoch [763/2000], Loss: 0.0885682246634658\n",
      "Epoch [764/2000], Loss: 0.08834577036995284\n",
      "Epoch [765/2000], Loss: 0.08855796591356886\n",
      "Epoch [766/2000], Loss: 0.08844867740438578\n",
      "Epoch [767/2000], Loss: 0.08832904699962464\n",
      "Epoch [768/2000], Loss: 0.0883529511206027\n",
      "Epoch [769/2000], Loss: 0.08838709762118792\n",
      "Epoch [770/2000], Loss: 0.08867711349971977\n",
      "Epoch [771/2000], Loss: 0.08862431718150215\n",
      "Epoch [772/2000], Loss: 0.08839554490058076\n",
      "Epoch [773/2000], Loss: 0.08852017433010916\n",
      "Epoch [774/2000], Loss: 0.08844709172495094\n",
      "Epoch [775/2000], Loss: 0.08829840325133902\n",
      "Epoch [776/2000], Loss: 0.088337897624768\n",
      "Epoch [777/2000], Loss: 0.08837003918460837\n",
      "Epoch [778/2000], Loss: 0.08836312196764028\n",
      "Epoch [779/2000], Loss: 0.08839847357340262\n",
      "Epoch [780/2000], Loss: 0.0883813749806422\n",
      "Epoch [781/2000], Loss: 0.08849663546247662\n",
      "Epoch [782/2000], Loss: 0.08830612754457993\n",
      "Epoch [783/2000], Loss: 0.08823160603292671\n",
      "Epoch [784/2000], Loss: 0.08851197372439881\n",
      "Epoch [785/2000], Loss: 0.08844972202475641\n",
      "Epoch [786/2000], Loss: 0.08823348308952761\n",
      "Epoch [787/2000], Loss: 0.08832072578545468\n",
      "Epoch [788/2000], Loss: 0.08847794216563444\n",
      "Epoch [789/2000], Loss: 0.08846893427377575\n",
      "Epoch [790/2000], Loss: 0.08832422510978762\n",
      "Epoch [791/2000], Loss: 0.08841023314306994\n",
      "Epoch [792/2000], Loss: 0.08819606120177838\n",
      "Epoch [793/2000], Loss: 0.08835630391685056\n",
      "Epoch [794/2000], Loss: 0.08846046359326358\n",
      "Epoch [795/2000], Loss: 0.08838387722140746\n",
      "Epoch [796/2000], Loss: 0.08840338438049729\n",
      "Epoch [797/2000], Loss: 0.08837061273939732\n",
      "Epoch [798/2000], Loss: 0.08828208679464501\n",
      "Epoch [799/2000], Loss: 0.08849348855410383\n",
      "Epoch [800/2000], Loss: 0.08823876876926198\n",
      "Epoch [801/2000], Loss: 0.08820543438196182\n",
      "Epoch [802/2000], Loss: 0.08833942118105194\n",
      "Epoch [803/2000], Loss: 0.08825716180420817\n",
      "Epoch [804/2000], Loss: 0.08842038583587593\n",
      "Epoch [805/2000], Loss: 0.08843922999823037\n",
      "Epoch [806/2000], Loss: 0.08862960614928617\n",
      "Epoch [807/2000], Loss: 0.08878450630836084\n",
      "Epoch [808/2000], Loss: 0.08851135434679022\n",
      "Epoch [809/2000], Loss: 0.08864594502768046\n",
      "Epoch [810/2000], Loss: 0.08848536738627394\n",
      "Epoch [811/2000], Loss: 0.08836369076525101\n",
      "Epoch [812/2000], Loss: 0.08816884895305678\n",
      "Epoch [813/2000], Loss: 0.08822302296407905\n",
      "Epoch [814/2000], Loss: 0.08823360894487497\n",
      "Epoch [815/2000], Loss: 0.0884679493979669\n",
      "Epoch [816/2000], Loss: 0.08820676565729955\n",
      "Epoch [817/2000], Loss: 0.08833909846247642\n",
      "Epoch [818/2000], Loss: 0.08845903787394645\n",
      "Epoch [819/2000], Loss: 0.0883829094854319\n",
      "Epoch [820/2000], Loss: 0.08836908694444127\n",
      "Epoch [821/2000], Loss: 0.08831274932678876\n",
      "Epoch [822/2000], Loss: 0.08831877579711413\n",
      "Epoch [823/2000], Loss: 0.08862617965175512\n",
      "Epoch [824/2000], Loss: 0.08819939189113922\n",
      "Epoch [825/2000], Loss: 0.08803256915908464\n",
      "Epoch [826/2000], Loss: 0.08830238787780904\n",
      "Epoch [827/2000], Loss: 0.08826037405382299\n",
      "Epoch [828/2000], Loss: 0.08851223292065338\n",
      "Epoch [829/2000], Loss: 0.08835231586241386\n",
      "Epoch [830/2000], Loss: 0.08831865802197389\n",
      "Epoch [831/2000], Loss: 0.08827352275451024\n",
      "Epoch [832/2000], Loss: 0.08835350340800666\n",
      "Epoch [833/2000], Loss: 0.08826595153047445\n",
      "Epoch [834/2000], Loss: 0.08847240362089005\n",
      "Epoch [835/2000], Loss: 0.08825389323799823\n",
      "Epoch [836/2000], Loss: 0.08829567969684869\n",
      "Epoch [837/2000], Loss: 0.08820769883377451\n",
      "Epoch [838/2000], Loss: 0.08851647852731982\n",
      "Epoch [839/2000], Loss: 0.08809701007016947\n",
      "Epoch [840/2000], Loss: 0.08835269230911989\n",
      "Epoch [841/2000], Loss: 0.08817129697598203\n",
      "Epoch [842/2000], Loss: 0.08842324252139794\n",
      "Epoch [843/2000], Loss: 0.0883948382147601\n",
      "Epoch [844/2000], Loss: 0.08812208501665805\n",
      "Epoch [845/2000], Loss: 0.0880946955630477\n",
      "Epoch [846/2000], Loss: 0.08822557700911599\n",
      "Epoch [847/2000], Loss: 0.08817552502306414\n",
      "Epoch [848/2000], Loss: 0.08849405507806321\n",
      "Epoch [849/2000], Loss: 0.08819863948743668\n",
      "Epoch [850/2000], Loss: 0.08834153756569249\n",
      "Epoch [851/2000], Loss: 0.08803794522520522\n",
      "Epoch [852/2000], Loss: 0.08809795947701718\n",
      "Epoch [853/2000], Loss: 0.08832886678652024\n",
      "Epoch [854/2000], Loss: 0.08823903678028797\n",
      "Epoch [855/2000], Loss: 0.0882723717622354\n",
      "Epoch [856/2000], Loss: 0.08829701174172996\n",
      "Epoch [857/2000], Loss: 0.08840269693326502\n",
      "Epoch [858/2000], Loss: 0.08823340512077574\n",
      "Epoch [859/2000], Loss: 0.08850411171784424\n",
      "Epoch [860/2000], Loss: 0.08799088557421321\n",
      "Epoch [861/2000], Loss: 0.0881497261110046\n",
      "Epoch [862/2000], Loss: 0.08828282940415709\n",
      "Epoch [863/2000], Loss: 0.08820877245194475\n",
      "Epoch [864/2000], Loss: 0.08812353021941834\n",
      "Epoch [865/2000], Loss: 0.08819724801280689\n",
      "Epoch [866/2000], Loss: 0.08828681305120809\n",
      "Epoch [867/2000], Loss: 0.08823845755886024\n",
      "Epoch [868/2000], Loss: 0.08831632763427189\n",
      "Epoch [869/2000], Loss: 0.08824462065814247\n",
      "Epoch [870/2000], Loss: 0.0880216199537398\n",
      "Epoch [871/2000], Loss: 0.08807888662031559\n",
      "Epoch [872/2000], Loss: 0.08825362309323789\n",
      "Epoch [873/2000], Loss: 0.08817530916610235\n",
      "Epoch [874/2000], Loss: 0.08826163939327142\n",
      "Epoch [875/2000], Loss: 0.088160225693049\n",
      "Epoch [876/2000], Loss: 0.08812258889277776\n",
      "Epoch [877/2000], Loss: 0.08834483911733672\n",
      "Epoch [878/2000], Loss: 0.08814046084181244\n",
      "Epoch [879/2000], Loss: 0.08792217981787355\n",
      "Epoch [880/2000], Loss: 0.08820083433053863\n",
      "Epoch [881/2000], Loss: 0.08806430635877618\n",
      "Epoch [882/2000], Loss: 0.08809090199325006\n",
      "Epoch [883/2000], Loss: 0.08809828387459678\n",
      "Epoch [884/2000], Loss: 0.08815796582351827\n",
      "Epoch [885/2000], Loss: 0.08799738531381311\n",
      "Epoch [886/2000], Loss: 0.08799061385538656\n",
      "Epoch [887/2000], Loss: 0.08808599793715097\n",
      "Epoch [888/2000], Loss: 0.0879551124334895\n",
      "Epoch [889/2000], Loss: 0.0882242671760595\n",
      "Epoch [890/2000], Loss: 0.0880621259970844\n",
      "Epoch [891/2000], Loss: 0.0881814783867536\n",
      "Epoch [892/2000], Loss: 0.08808237957842473\n",
      "Epoch [893/2000], Loss: 0.08813211811540272\n",
      "Epoch [894/2000], Loss: 0.08826592585570375\n",
      "Epoch [895/2000], Loss: 0.08809543547915741\n",
      "Epoch [896/2000], Loss: 0.08821618221175502\n",
      "Epoch [897/2000], Loss: 0.08801275998913625\n",
      "Epoch [898/2000], Loss: 0.08799833867331626\n",
      "Epoch [899/2000], Loss: 0.08827173835794691\n",
      "Epoch [900/2000], Loss: 0.08820232318740495\n",
      "Epoch [901/2000], Loss: 0.08801206134854347\n",
      "Epoch [902/2000], Loss: 0.0880177540468498\n",
      "Epoch [903/2000], Loss: 0.08795549419704178\n",
      "Epoch [904/2000], Loss: 0.08803995436346027\n",
      "Epoch [905/2000], Loss: 0.08817864496243392\n",
      "Epoch [906/2000], Loss: 0.08818324235543398\n",
      "Epoch [907/2000], Loss: 0.08809943839977605\n",
      "Epoch [908/2000], Loss: 0.08813101438009682\n",
      "Epoch [909/2000], Loss: 0.08832180160731777\n",
      "Epoch [910/2000], Loss: 0.08825116936869465\n",
      "Epoch [911/2000], Loss: 0.08821592133649638\n",
      "Epoch [912/2000], Loss: 0.08808719828514985\n",
      "Epoch [913/2000], Loss: 0.08797907717351063\n",
      "Epoch [914/2000], Loss: 0.08799808437415692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [915/2000], Loss: 0.08807599068807324\n",
      "Epoch [916/2000], Loss: 0.0881255868594971\n",
      "Epoch [917/2000], Loss: 0.08814322567181967\n",
      "Epoch [918/2000], Loss: 0.08789559894464385\n",
      "Epoch [919/2000], Loss: 0.08806683896153186\n",
      "Epoch [920/2000], Loss: 0.08796799424248682\n",
      "Epoch [921/2000], Loss: 0.08797962061116393\n",
      "Epoch [922/2000], Loss: 0.08805180589358012\n",
      "Epoch [923/2000], Loss: 0.0881583226818434\n",
      "Epoch [924/2000], Loss: 0.08809212192962987\n",
      "Epoch [925/2000], Loss: 0.08783590268920845\n",
      "Epoch [926/2000], Loss: 0.0881001826882922\n",
      "Epoch [927/2000], Loss: 0.08784503773064681\n",
      "Epoch [928/2000], Loss: 0.08813163666098331\n",
      "Epoch [929/2000], Loss: 0.0881120234098233\n",
      "Epoch [930/2000], Loss: 0.08815342964420855\n",
      "Epoch [931/2000], Loss: 0.08833822461081223\n",
      "Epoch [932/2000], Loss: 0.08824815436707975\n",
      "Epoch [933/2000], Loss: 0.08806705915592086\n",
      "Epoch [934/2000], Loss: 0.08797142056512161\n",
      "Epoch [935/2000], Loss: 0.08807227865491114\n",
      "Epoch [936/2000], Loss: 0.08798038742631814\n",
      "Epoch [937/2000], Loss: 0.08795545026310173\n",
      "Epoch [938/2000], Loss: 0.0880054235458374\n",
      "Epoch [939/2000], Loss: 0.08797029307890386\n",
      "Epoch [940/2000], Loss: 0.08799323527046213\n",
      "Epoch [941/2000], Loss: 0.08778246387209691\n",
      "Epoch [942/2000], Loss: 0.08793777332339488\n",
      "Epoch [943/2000], Loss: 0.0880404520832317\n",
      "Epoch [944/2000], Loss: 0.08801316823198202\n",
      "Epoch [945/2000], Loss: 0.08791780909042403\n",
      "Epoch [946/2000], Loss: 0.08789753165323409\n",
      "Epoch [947/2000], Loss: 0.08800179112545202\n",
      "Epoch [948/2000], Loss: 0.08800821296625853\n",
      "Epoch [949/2000], Loss: 0.08782680563523736\n",
      "Epoch [950/2000], Loss: 0.08788614198915276\n",
      "Epoch [951/2000], Loss: 0.08795333181468534\n",
      "Epoch [952/2000], Loss: 0.08798378331700402\n",
      "Epoch [953/2000], Loss: 0.08799458081733452\n",
      "Epoch [954/2000], Loss: 0.08797177661892394\n",
      "Epoch [955/2000], Loss: 0.08816952562667954\n",
      "Epoch [956/2000], Loss: 0.08796433915554637\n",
      "Epoch [957/2000], Loss: 0.08780187679708285\n",
      "Epoch [958/2000], Loss: 0.08806340448873144\n",
      "Epoch [959/2000], Loss: 0.08791036505094717\n",
      "Epoch [960/2000], Loss: 0.08781831777991264\n",
      "Epoch [961/2000], Loss: 0.08786408557718349\n",
      "Epoch [962/2000], Loss: 0.08791461209176292\n",
      "Epoch [963/2000], Loss: 0.08780963362102777\n",
      "Epoch [964/2000], Loss: 0.08785029185909621\n",
      "Epoch [965/2000], Loss: 0.08784349318681188\n",
      "Epoch [966/2000], Loss: 0.08791845830533426\n",
      "Epoch [967/2000], Loss: 0.0878475181093798\n",
      "Epoch [968/2000], Loss: 0.08786562525890243\n",
      "Epoch [969/2000], Loss: 0.08805329447061243\n",
      "Epoch [970/2000], Loss: 0.08781981233839697\n",
      "Epoch [971/2000], Loss: 0.08780987963010448\n",
      "Epoch [972/2000], Loss: 0.08784400332421764\n",
      "Epoch [973/2000], Loss: 0.08780001352230708\n",
      "Epoch [974/2000], Loss: 0.08782511365385683\n",
      "Epoch [975/2000], Loss: 0.08803749689613709\n",
      "Epoch [976/2000], Loss: 0.08792007119862687\n",
      "Epoch [977/2000], Loss: 0.0877787266188944\n",
      "Epoch [978/2000], Loss: 0.08780301712068593\n",
      "Epoch [979/2000], Loss: 0.08767158496128001\n",
      "Epoch [980/2000], Loss: 0.08780982107483724\n",
      "Epoch [981/2000], Loss: 0.08737276809316286\n",
      "Epoch [982/2000], Loss: 0.08810748726549283\n",
      "Epoch [983/2000], Loss: 0.08803583268828236\n",
      "Epoch [984/2000], Loss: 0.08801479266842765\n",
      "Epoch [985/2000], Loss: 0.08787602025298445\n",
      "Epoch [986/2000], Loss: 0.08793924038818744\n",
      "Epoch [987/2000], Loss: 0.08792671533257748\n",
      "Epoch [988/2000], Loss: 0.08792632440446128\n",
      "Epoch [989/2000], Loss: 0.08787829208541924\n",
      "Epoch [990/2000], Loss: 0.0876187380980438\n",
      "Epoch [991/2000], Loss: 0.08770953083821866\n",
      "Epoch [992/2000], Loss: 0.08772369162857252\n",
      "Epoch [993/2000], Loss: 0.08797335544242546\n",
      "Epoch [994/2000], Loss: 0.08798025723354358\n",
      "Epoch [995/2000], Loss: 0.0878532728608785\n",
      "Epoch [996/2000], Loss: 0.08791271786034947\n",
      "Epoch [997/2000], Loss: 0.08781810800934062\n",
      "Epoch [998/2000], Loss: 0.08776787434105582\n",
      "Epoch [999/2000], Loss: 0.08765741444669418\n",
      "Epoch [1000/2000], Loss: 0.08800212192423466\n",
      "Epoch [1001/2000], Loss: 0.08774736841939425\n",
      "Epoch [1002/2000], Loss: 0.08789417158130189\n",
      "Epoch [1003/2000], Loss: 0.08794451910705074\n",
      "Epoch [1004/2000], Loss: 0.08786150624214763\n",
      "Epoch [1005/2000], Loss: 0.08801709979492733\n",
      "Epoch [1006/2000], Loss: 0.08765107645115382\n",
      "Epoch [1007/2000], Loss: 0.08794768081164696\n",
      "Epoch [1008/2000], Loss: 0.08770742760577672\n",
      "Epoch [1009/2000], Loss: 0.08791739532085652\n",
      "Epoch [1010/2000], Loss: 0.0879443616304599\n",
      "Epoch [1011/2000], Loss: 0.08785970414608298\n",
      "Epoch [1012/2000], Loss: 0.0878029690591942\n",
      "Epoch [1013/2000], Loss: 0.08765806999284896\n",
      "Epoch [1014/2000], Loss: 0.08772537843302382\n",
      "Epoch [1015/2000], Loss: 0.08773241608355527\n",
      "Epoch [1016/2000], Loss: 0.08808539234136752\n",
      "Epoch [1017/2000], Loss: 0.087750686586183\n",
      "Epoch [1018/2000], Loss: 0.08766928927299562\n",
      "Epoch [1019/2000], Loss: 0.08766547821357216\n",
      "Epoch [1020/2000], Loss: 0.0877828268867703\n",
      "Epoch [1021/2000], Loss: 0.0877356351891034\n",
      "Epoch [1022/2000], Loss: 0.08750170241918923\n",
      "Epoch [1023/2000], Loss: 0.08760792233854392\n",
      "Epoch [1024/2000], Loss: 0.08787835252956605\n",
      "Epoch [1025/2000], Loss: 0.08765282653307131\n",
      "Epoch [1026/2000], Loss: 0.08767675723828061\n",
      "Epoch [1027/2000], Loss: 0.087619241904205\n",
      "Epoch [1028/2000], Loss: 0.08779868840331763\n",
      "Epoch [1029/2000], Loss: 0.08782689784054465\n",
      "Epoch [1030/2000], Loss: 0.08757462744281885\n",
      "Epoch [1031/2000], Loss: 0.08779407887251724\n",
      "Epoch [1032/2000], Loss: 0.08762341429929778\n",
      "Epoch [1033/2000], Loss: 0.08751390496609916\n",
      "Epoch [1034/2000], Loss: 0.08775022006790403\n",
      "Epoch [1035/2000], Loss: 0.0874509483295987\n",
      "Epoch [1036/2000], Loss: 0.0876107081910814\n",
      "Epoch [1037/2000], Loss: 0.0876283758962658\n",
      "Epoch [1038/2000], Loss: 0.08772313731237197\n",
      "Epoch [1039/2000], Loss: 0.08759710622925154\n",
      "Epoch [1040/2000], Loss: 0.08806790149127933\n",
      "Epoch [1041/2000], Loss: 0.08771684409027368\n",
      "Epoch [1042/2000], Loss: 0.08757308380844447\n",
      "Epoch [1043/2000], Loss: 0.08777311063008689\n",
      "Epoch [1044/2000], Loss: 0.087747760676722\n",
      "Epoch [1045/2000], Loss: 0.0875863513336495\n",
      "Epoch [1046/2000], Loss: 0.08757162884647297\n",
      "Epoch [1047/2000], Loss: 0.08769807048106977\n",
      "Epoch [1048/2000], Loss: 0.08768292142191964\n",
      "Epoch [1049/2000], Loss: 0.08779126902421315\n",
      "Epoch [1050/2000], Loss: 0.08776696043814852\n",
      "Epoch [1051/2000], Loss: 0.087554571739105\n",
      "Epoch [1052/2000], Loss: 0.08789648182095497\n",
      "Epoch [1053/2000], Loss: 0.08765674207551938\n",
      "Epoch [1054/2000], Loss: 0.08773517195887409\n",
      "Epoch [1055/2000], Loss: 0.08764039592144075\n",
      "Epoch [1056/2000], Loss: 0.08781208384764587\n",
      "Epoch [1057/2000], Loss: 0.08757400236359225\n",
      "Epoch [1058/2000], Loss: 0.08768018146216029\n",
      "Epoch [1059/2000], Loss: 0.08761667309792388\n",
      "Epoch [1060/2000], Loss: 0.08766208428172438\n",
      "Epoch [1061/2000], Loss: 0.08747872913107625\n",
      "Epoch [1062/2000], Loss: 0.08748994263964639\n",
      "Epoch [1063/2000], Loss: 0.08754527859144927\n",
      "Epoch [1064/2000], Loss: 0.08785888087441664\n",
      "Epoch [1065/2000], Loss: 0.08782009944809435\n",
      "Epoch [1066/2000], Loss: 0.0878149580927522\n",
      "Epoch [1067/2000], Loss: 0.08764036104712687\n",
      "Epoch [1068/2000], Loss: 0.08789524282088303\n",
      "Epoch [1069/2000], Loss: 0.0876304342503279\n",
      "Epoch [1070/2000], Loss: 0.08787159740645001\n",
      "Epoch [1071/2000], Loss: 0.08771315384918535\n",
      "Epoch [1072/2000], Loss: 0.08787332531152196\n",
      "Epoch [1073/2000], Loss: 0.08761589204621427\n",
      "Epoch [1074/2000], Loss: 0.08735973853180666\n",
      "Epoch [1075/2000], Loss: 0.08785027842706358\n",
      "Epoch [1076/2000], Loss: 0.08755365472304429\n",
      "Epoch [1077/2000], Loss: 0.08756557348328577\n",
      "Epoch [1078/2000], Loss: 0.0877329933461449\n",
      "Epoch [1079/2000], Loss: 0.08766188783824724\n",
      "Epoch [1080/2000], Loss: 0.08762681851504554\n",
      "Epoch [1081/2000], Loss: 0.0875984249820172\n",
      "Epoch [1082/2000], Loss: 0.08775974904567423\n",
      "Epoch [1083/2000], Loss: 0.08734511674989558\n",
      "Epoch [1084/2000], Loss: 0.08756039735856751\n",
      "Epoch [1085/2000], Loss: 0.08768649304836569\n",
      "Epoch [1086/2000], Loss: 0.08762378962666775\n",
      "Epoch [1087/2000], Loss: 0.08756318835305496\n",
      "Epoch [1088/2000], Loss: 0.08772886324096733\n",
      "Epoch [1089/2000], Loss: 0.08715964458498036\n",
      "Epoch [1090/2000], Loss: 0.08744312955739912\n",
      "Epoch [1091/2000], Loss: 0.08757042818366081\n",
      "Epoch [1092/2000], Loss: 0.08767280248409146\n",
      "Epoch [1093/2000], Loss: 0.08760959847432347\n",
      "Epoch [1094/2000], Loss: 0.08728942771752675\n",
      "Epoch [1095/2000], Loss: 0.0874717267046512\n",
      "Epoch [1096/2000], Loss: 0.08757008703101969\n",
      "Epoch [1097/2000], Loss: 0.08744199171732289\n",
      "Epoch [1098/2000], Loss: 0.08755157831968836\n",
      "Epoch [1099/2000], Loss: 0.08780001086388395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1100/2000], Loss: 0.08744589564665942\n",
      "Epoch [1101/2000], Loss: 0.08739130031055128\n",
      "Epoch [1102/2000], Loss: 0.08754585211125898\n",
      "Epoch [1103/2000], Loss: 0.08759807393024785\n",
      "Epoch [1104/2000], Loss: 0.08775297730741366\n",
      "Epoch [1105/2000], Loss: 0.08755003220178711\n"
     ]
    }
   ],
   "source": [
    "model = AutoencoderCNN().to(device)\n",
    "print(model)\n",
    "# 손실 함수 및 최적화 기준 설정\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 모델 학습\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        images = data\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60256c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = running_loss/len(train_loader.dataset)\n",
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eeeb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset2 = CustomDataset(csv_file=os.path.join(path,\"train.csv\"), transform=transform_test)\n",
    "train_loader2 = DataLoader(train_dataset2, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "test_pred = []\n",
    "loss_list = []\n",
    "with torch.no_grad():\n",
    "    for data in train_loader2:\n",
    "        images = data\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images).to(device).item()\n",
    "        loss_list.append(loss)\n",
    "# print(loss_list)\n",
    "plt.hist(loss_list)\n",
    "plt.show()\n",
    "print(np.mean(loss_list))\n",
    "m1 = np.percentile(np.array(loss_list), 50, axis=0)\n",
    "print(m1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(csv_file=os.path.join(path,\"test.csv\"), transform=transform_test)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "test_pred = []\n",
    "loss_list = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images = data\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images).to(device).item()\n",
    "        loss_list.append(loss)\n",
    "        if loss<=m1 :#or loss>=m2:\n",
    "            test_pred.append(0.)\n",
    "        else:\n",
    "            test_pred.append(1.)\n",
    "plt.hist(loss_list)\n",
    "plt.show()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5801f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = [0,1,0,0,0,0,1,0,0,1,0,1,0,0,1,1,0,0,0,0,0,0,1,1,1,0,1,0,0,1,1,1,0,0,1,0,0,0,1,1,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,1,0,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1,1,1,1,1,1,0,0,1,1]\n",
    "cf_matrix = confusion_matrix(answer, test_pred)\n",
    "group_names = [\"TN\", \"FP (type  II error)\", \"FN (type I error)\", \"TP\"]\n",
    "group_counts = [value for value in cf_matrix.flatten()]\n",
    "group_percentages = [f\"{value:.1%}\" for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n({v3})\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "labels\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a838424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(os.path.join(path,\"sample_submission.csv\"))\n",
    "submit['label'] = test_pred\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190baa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(os.path.join(save_path,\"submit63.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d6396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
